---
title: 'AI e Engenharia de Contexto (Context Engineering) em um projeto do zero com vibe coding'
date: 2025-08-20 00:00:01
description: 'Me rendi ao vibe coding e criei uma aplica√ß√£o inteira em 5 minutos! S√≥ que n√£o üòÖ'
image: /assets/2025-08-20-cover.jpg
tags: ['ai', 'front-end', 'programa√ß√£o']
---

Faz pelo menos 2 anos que tenho usado ativamente LLMs para criar c√≥digo, geralmente para entregar features em projetos que j√° existiam.

Dito isso passei o √∫ltimo m√™s completamente imerso usando **vibe coding** pra criar uma aplica√ß√£o de mundo real, complexa e do zero, com **Next.js + TypeScript**.  

Aqui v√£o minhas percep√ß√µes sobre ferramentas, modelos e workflows que usei nesse processo:  

## ‚û°Ô∏è Ferramentas usadas  

### VS Code + Copilot  

Usei esse combo por muito tempo e, no geral, funcionava bem.  

O problema √© que como na vida, pra cada vislumbre de felicidade, precisamos lidar com decep√ß√µes e frustra√ß√µes:  

- O **Sonnet 4** ganhou limite de tokens.  
- O **GPT 4.1 ilimitado do Copilot** √© pregui√ßoso e alucina tanto que poderia ser chamado de *Burrice Artificial*.  

E de burro e pregui√ßoso basta eu.  

https://twitter.com/felipefialho_/status/1947395637579788501

### Cursor  

Foi amor no primeiro prompt.  

O **modo auto ilimitado** funciona muito bem, permitindo alternar pro Sonnet 4 em tarefas complexas e voltar pro auto nas mais simples.  

Resultado: um workflow eficiente e econ√¥mico em tokens.  

Al√©m disso, a **DX √© absurdamente boa**, especialmente pra quem trabalha com front-end.  

## ‚û°Ô∏è LLMs usadas  

- **Claude Sonnet 4** ‚Äì Melhor output geral, entende o contexto do projeto, segue instru√ß√µes mesmo com prompts simples.  
- **Claude Opus 4.1** ‚Äì Gasta tokens como um Opala bebe gasolina mas consegue resultados impressionantes, vale usar pra tarefas muito complexas ou pra trabalhar na estrutura inicial da aplica√ß√£o.  
- **Modo auto (Cursor)** ‚Äì Supostamente escolhe o melhor custo benef√≠cio pra sua tarefa, vi muita gente falando mal mas funcionou muito bem pra mim, especialmente depois da aplica√ß√£o estar mais estruturada. 
- **GPT 5** ‚Äì Mais r√°pido e com menos alucina√ß√µes que o 4.1, mas ainda atr√°s do Sonnet 4 pra front-end.  
- **GPT 4.1** ‚Äì Intrag√°vel: outputs ruins, cortados pela metade e sem entender contexto.  

Tamb√©m testei **o4 mini, Gemini 2.5 e Grok 2**, mas por pouco tempo pra tirar conclus√µes s√≥lidas.  

## ‚û°Ô∏è Engenharia de Contexto (Context Engineering)

Esse termo se popularizou r√°pido, e com raz√£o. 

√â basicamente **preparar o terreno** para que as LLMs sejam mais eficientes.

N√£o √© s√≥ escrever um bom prompt.

Em vez de simplesmente fazer uma pergunta, voc√™ fornece ao modelo o contexto, a persona e as instru√ß√µes necess√°rias para gerar a sa√≠da desejada. 

No mundo da programa√ß√£o, isso √© crucial para transformar uma LLM de uma ferramenta gen√©rica pra um assistente de c√≥digo que realmente vai te ajudar no mundo real.

A ideia √© dar a eles **exatamente o que precisam**, a informa√ß√£o certa, no formato ideal e no momento certo para que as respostas sejam precisas e controladas. Ou seja, construir um sistema que monta dinamicamente um workflow completo.

Isso inclui: 

- Documenta√ß√£o e arquivos relevantes  
- Formato esperado do output  
- Contexto hist√≥rico  
- Exemplos de c√≥digo
- Instru√ß√µes claras  

### O que pode ajudar na engenharia de contexto?

A engenharia de contexto vai al√©m de apenas dar instru√ß√µes claras. Ao fornecer informa√ß√µes adicionais, voc√™ ajuda o LLM a entender melhor seu input, o que resulta num output mais preciso.

**1. Forne√ßa uma Persona para o LLM**

Ao atribuir um "papel" ao LLM, voc√™ o direciona a adotar uma perspectiva e um tom espec√≠ficos. Isso √© especialmente √∫til para tarefas que exigem um estilo de comunica√ß√£o particular.

*Exemplo de Prompt com Persona*: 

> You are an expert full-stack developer with 15 years of experience specializing in Node.js backend APIs. You always follow best practices and prioritize security and performance. Your task is to write a fast and efficient function to handle HTTP POST requests that creates a new user.

Usando persona de "desenvolvedor experiente" voc√™ orienta o LLM a gerar c√≥digo de alta qualidade seguindo as conven√ß√µes e boas pr√°ticas da linguagem, em vez de um c√≥digo gen√©rico.

**2. D√™ Exemplos de Input e Output (Few-Shot Learning)**

Mostrar ao LLM como voc√™ quer que a resposta seja formatada pode reduzir drasticamente o risco de "alucinar" ou retornar um resultado fora do padr√£o.

Isso √© conhecido como "few-shot learning".

**Prompt com Exemplos:** 

>`Given a URL, extract the domain name.
>
> Input: 'https://www.google.com/search'
> Output: 'https://www.google.com/search?q=google.com'
>
> Input: 'https://github.com/microsoft'
> Output: 'github.com'
>
> Input: 'http://my-blog.com'
> Output: 'my-blog.com'

Com isso o LLM aprende o padr√£o da sua solicita√ß√£o pelos exemplos. Isso garante que a resposta ser√° consistente e no formato desejado.

**3. Inclua TODAS as Restri√ß√µes e Limita√ß√µes**

Definir o que o LLM n√£o deve fazer √© t√£o importante quanto dizer o que ele deve fazer.

**Prompt com Restri√ß√µes:** 

> Write a simple JavaScript script to read a JSON file and print its contents. The script must NOT use any external libraries like 'fs-extra' or 'lodash'. Use only built-in Node.js modules.

A instru√ß√£o de "n√£o usar bibliotecas externas" evita que o LLM gere um c√≥digo que possa ser incompat√≠vel com o seu ambiente de projeto.

**4. Estruture seu Prompt**

A clareza √© fundamental. Usar uma estrutura clara, como a marca√ß√£o Markdown, ajuda a organizar o seu pedido em se√ß√µes l√≥gicas.

**Prompt Estruturado:**

> Task
> Write a simple JavaScript function to sort a list of numbers.
> Context
> The list can contain positive and negative integers.
> Constraints
> Do not use the built-in 'sort()' method. Implement a sorting algorithm from scratch.
> Desired Output Format
> The function should return a sorted list.

A organiza√ß√£o do prompt em se√ß√µes ( Task, Context, Constraints e Desired Output Format) faz ficar mais f√°cil de ser lido pelo LLM, diminuindo a chance de ele pular alguma instru√ß√£o importante.

**5. Crie um arquivo de contexto**

Para prompts mais complexos ou que exigem informa√ß√µes de diversos arquivos, voc√™ pode criar um arquivo de texto, como `context.md`, com o seu prompt detalhado e carreg√°-lo no LLM. Isso √© √∫til para:

- **Reutiliza√ß√£o:** Voc√™ pode salvar e reutilizar prompts complexos para tarefas recorrentes.
- **Organiza√ß√£o:** Mant√©m seu prompt limpo e bem-estruturado.
- **Colabora√ß√£o:** Permite que outros membros da equipe usem o mesmo contexto para obter respostas consistentes.

Dessa forma em vez de digitar um prompt longo toda vez, voc√™ pode simplesmente carregar o arquivo, garantindo que todas as instru√ß√µes e o contexto sejam fornecidos de forma consistente.

Ferramentas como Cursor e Copilot permitem carregar arquivos como contexto adicionando em pastas de contexto, vale ler a documenta√ß√£o de cada uma delas.

**6. Adicione arquivos do seu projeto como contexto**

Essa √© uma maneira mais poderosa de fornecer contexto. Isso permite que o LLM analise a arquitetura de c√≥digo, as depend√™ncias, as conven√ß√µes de nomenclatura e outros detalhes que seriam dif√≠ceis de descrever manualmente.

**Cen√°rio:** Voc√™ precisa que o LLM crie um novo componente para o seu projeto React.

**A√ß√£o:** Adicione o arquivo package.json para que o LLM entenda as depend√™ncias. Em seguida, adicione o arquivo UserComponent.js e UserComponent.scss para que o LLM entenda o estilo de c√≥digo atual e as classes CSS que voc√™ j√° est√° usando.

**Prompt ap√≥s o upload:**

> Given the context from the files I've uploaded, create a new 'ProductCard' component. It should follow the same structure and coding style as 'UserComponent.js' and use classes from the 'UserComponent.scss' file to maintain a consistent look.

A capacidade de "ver" os arquivos de contexto permite que o LLM gere um c√≥digo que se integra perfeitamente ao seu projeto existente, economizando tempo de refatora√ß√£o e minimizando erros.

### Exemplo 1: Gerando C√≥digo com Especifica√ß√µes Detalhadas

Voc√™ precisa de uma fun√ß√£o em JavaScript para validar um endere√ßo de e-mail. Uma solicita√ß√£o simples pode at√© funcionar, mas n√£o garante a precis√£o ou o formato do c√≥digo.

**Prompt Simples** (baixa qualidade)

> Write a JavaScript function to validate an email address.

**Prompt com Contexto** (boa qualidade)

> "As a senior JavaScript developer specializing in front-end performance, your task is to create a function to validate email addresses.
>
>The function, named 'validateEmail', should accept a single string parameter 'email'. It must use a minimal regular expression for validation to ensure maximum performance and avoid unnecessary complexity. The function should return a boolean value and include comprehensive JSDoc comments describing its purpose, parameters, and return value
>
> After the function, please write unit tests using Jest to cover the following cases:
>
> - A valid email address.
> - An invalid email address (e.g., missing '@').
> - An empty string.
> - A null or undefined value.
> 
> Finally, provide a clear usage example with one valid email and one invalid email"

Este prompt n√£o apenas pede o c√≥digo, mas tamb√©m define a assinatura da fun√ß√£o, o m√©todo a ser usado (regex), o formato da sa√≠da (boolean), a necessidade de documenta√ß√£o (JSDoc) e um exemplo de uso. Isso elimina ambiguidades e garante que o c√≥digo gerado atenda a requisitos espec√≠ficos.

### Exemplo 2: Depurando Erros e Otimizando C√≥digo

Voc√™ tem um trecho de c√≥digo JavaScript que est√° falhando, mas a mensagem de erro n√£o √© clara.

```js
const data = null;
const evenNumbers = data.filter(num => num % 2 === 0);
console.log(evenNumbers);
```

**Prompt Simples** (baixa qualidade)

> Why is this JavaScript code not working? [code snippet]

Nesse cen√°rio, o LLM vai te dizer que data √© nulo, algo que a pr√≥pria mensagem de erro j√° aponta. O resultado √© uma resposta gen√©rica e pouco √∫til.

**Prompt com Contexto** (boa qualidade)

> Analyze the following JavaScript code. It's supposed to iterate over an array of numbers and return only the even values. However, it's throwing a 'TypeError: Cannot read properties of undefined' error. Identify the root cause of the error, provide the corrected code, and explain the bug. Also, suggest how the code can be refactored for better readability and performance.

Nesse cen√°rio voc√™ t√° fornecendo pro LLM a tarefa (identificar e corrigir um erro), o contexto (o objetivo do c√≥digo), a mensagem de erro exata e uma solicita√ß√£o adicional para otimiza√ß√£o.

Isso guia o modelo para uma an√°lise mais profunda e uma resposta mais completa.

### Exemplo 3: Refatorando e Adicionando Coment√°rios

Voc√™ tem um trecho de c√≥digo desorganizado e sem documenta√ß√£o que precisa ser melhorado.

```js
function process(a, b, c, d){
	if(c === 'sum'){
		return a + b
	} else if(c === 'subtract'){
		return a - b
	} else {
		return 'Error: Invalid operation'
	}
}
```

**Prompt Simples** (baixa qualidade)

> Improve this code. [code]

A AI at√© pode melhorar o c√≥digo, mas sem instru√ß√µes espec√≠ficas, o resultado ser√° gen√©rico e talvez n√£o atenda √†s suas expectativas.

**Prompt com Contexto** (boa qualidade)

> As an experienced software engineer specializing in clean and maintainable code, your task is to refactor the following JavaScript function.
>
> The refactored code should use descriptive variable names, apply modern coding practices like const and switch statements, and have proper indentation. Add JSDoc comments to document the function's purpose, parameters, and return value. The original functionality must be preserved.
>
> After the refactored code, provide a brief explanation of the key changes you made and why they improve the code's readability and maintainability.

Dessa forma o prompt detalha o que precisa ser feito (refatorar), o objetivo (melhorar legibilidade), as diretrizes (renomear vari√°veis, formata√ß√£o) e as restri√ß√µes (n√£o alterar a funcionalidade).

Isso transforma a tarefa de "melhorar" em um conjunto de instru√ß√µes claras e contextuais para o LLM.

### Resumindo

Ao fornecer as informa√ß√µes corretas, o prop√≥sito, a persona, as restri√ß√µes e o formato desejado e etc, voc√™ transforma o LLM em um parceiro de programa√ß√£o inteligente, capaz de gerar c√≥digo mais preciso, documentado e √∫til. 

Se voc√™ realmente deseja maximizar o poder dos LLMs em seu fluxo de trabalho, a engenharia de contexto n√£o √© apenas uma habilidade √∫til, mas sim uma necessidade.

Usei essa abordagem pra tentar extrair o m√°ximo das LLMs gastando menos recursos e esfor√ßo. E a diferen√ßa de qualidade quando o contexto t√° bem amarrado √© absurda.

E agora vou falar dessa experi√™ncia.

## ‚û°Ô∏è Fase 1 ‚Äì Scaffolding e Arquitetura  

Aqui foi onde enfrentei o maior desafio.  

Mesmo com prompts e contexto bem pensados, o modelo ainda n√£o tinha exemplos suficientes pra gerar bons outputs.  
Resultado: **c√≥digo gen√©rico, sem ader√™ncia ao projeto**.  

O jeito foi criar um volume inicial de exemplos e arquivos pra que a LLM pudesse se apoiar. Isso exige tempo e paci√™ncia.

A dica aqui √© usar Thinking LLMs como o Claude Opus 4.1, que s√£o mais caros e lentos mas entregam resultados muito melhores em etapas iniciais, quando o contexto √© mais fraco.

Nessa altura o modo Chat pode ser interessante pra fazer brainstorming sobre decis√µes de arquitetura e organiza√ß√£o do projeto.

E sem uma base s√≥lida de arquitetura, essa etapa pode simplesmente matar a escalabilidade antes mesmo da aplica√ß√£o ganhar vida.  

## ‚û°Ô∏è Fase 2 ‚Äì Implementa√ß√£o  

Com o scaffolding pronto, podemos come√ßar a implementar as features e aqui conseguimos ver todo o pot√™ncial que LLMs entregam no dia a dia

Features que facilmente durariam uma sprint inteira para serem desenvolvidas, agora podem ser entregues em algumas horas, j√° otimizadas, testadas e perform√°ticas (se voc√™ tiver conhecimentos pra direcionar o LLM, √© claro!).

Tarefas como escrever testes, documenta√ß√£o, etc, s√£o feitas em minutos.

Existe uma dist√¢ncia exponencial entre o que √© poss√≠vel fazer com LLMs e o que √© poss√≠vel fazer com um dev humano.

### O problema: CSS, UI e UX

Aqui a coisa complica.  

LLMs parecem ter uma **paix√£o estranha e t√≥xica por flexbox**, criando layouts desnecessariamente complexos.  

Sendo assim muitas vezes escrever CSS manualmente, como faziamos nos tempos dos ca√ßadores-coletores, foi mais r√°pido.  

Mas depois que o projeto j√° tinha padr√µes e exemplos bem definidos, os resultados tamb√©m melhoraram bastante.  

---

## ‚û°Ô∏è Desenvolvimento de software mudou  

O jogo mudou e n√£o tem mais volta.  

Cada vez mais vejo o termo **"Engenheiro de Prompt"** se popularizando. Vamos ser respons√°veis por criar prompts otimizados, estruturar workflows inteligentes e revisar cuidadosamente cada output.  

Mas n√£o existe milagre: 

Sem conhecimento t√©cnico e experi√™ncia acumulada, o resultado √© s√≥ acelerar os pr√≥prios erros. 

Engenharia de Contexto te faz parar de tratar AIs como uma simples ferramenta de suporte. Com essa abordagem ela se torna parte essencial no seu dia a dia

Voc√™ consegue c√≥digo mais preciso, documentado e √∫til, atingindo uma velocidade de desenvolvimento de features que seria imposs√≠vel ter escrevendo c√≥digo artesanal como faziam ca√ßadores-coletores.

Se voc√™ quer extrair o m√°ximo das ferramentas e ter mais efici√™ncia no seu dia a dia, isso n√£o √© mais opcional.
